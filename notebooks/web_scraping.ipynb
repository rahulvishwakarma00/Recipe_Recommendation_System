import requests
from bs4 import BeautifulSoup
import pandas as pd

def get_recipe_links(base_url, num_pages):
    links = []
    for page in range(1, num_pages + 1):
        url = f"{base_url}?page={page}"
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        recipe_tags = soup.find_all('a', class_='card__titleLink manual-link-behavior')
        for tag in recipe_tags:
            links.append(tag['href'])
    return links

def get_recipe_details(recipe_url):
    response = requests.get(recipe_url)
    soup = BeautifulSoup(response.text, 'html.parser')
    title = soup.find('h1', class_='headline heading-content').text
    ingredients = [li.text for li in soup.find_all('span', class_='ingredients-item-name')]
    return {'title': title, 'ingredients': ingredients}

base_url = 'https://www.allrecipes.com/recipes'
recipe_links = get_recipe_links(base_url, 5)
recipes = [get_recipe_details(link) for link in recipe_links]

df = pd.DataFrame(recipes)
df.to_csv('recipes.csv', index=False)

